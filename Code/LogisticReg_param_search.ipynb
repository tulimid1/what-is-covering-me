{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression parameter search\n",
    "\n",
    "Duncan Tulimieri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16}) \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import seaborn as sns\n",
    "# personal classes\n",
    "from ProcessData import ProcessForestData\n",
    "import savingfigR as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pLogisticRegression(ProcessForestData):\n",
    "    \n",
    "    penalty_options = ['l1', 'l2', 'elasticnet', 'none']\n",
    "    C_options = np.linspace(0.01, 1, 5)\n",
    "    intercept_options = [True, False]\n",
    "    l1_ratio_options = np.linspace(0, 1, 5)\n",
    "    \n",
    "    def __init__(self):\n",
    "        # method calls \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.load_data(perform_scale=True, sub_data_section='')\n",
    "        self.un_classifiers = np.unique(self.y_train)\n",
    "        # Raw data \n",
    "        start = time.time()\n",
    "        LR_trained_opt = self.optimize_LogisticRegression_params(self.X_train, self.y_train, self.penalty_options, self.C_options, self.intercept_options, self.l1_ratio_options)\n",
    "        LR_score = self.score_LogisticRegression(LR_trained_opt, self.X_test, self.y_test)\n",
    "        end = time.time()\n",
    "        print(f'Raw data LogisticRegression optimal score = {LR_score}')\n",
    "        print(f'Time taken = {end-start}')\n",
    "\n",
    "    # model\n",
    "    def train_LogisticRegression(self, X, y, penalty, C, fit_B0, l1_ratio):\n",
    "        if penalty == 'elasticnet':\n",
    "            return LogisticRegression(penalty=penalty, C=C, fit_intercept=fit_B0, l1_ratio=l1_ratio, n_jobs=4, solver='saga').fit(X, y)\n",
    "        else: \n",
    "            return LogisticRegression(penalty=penalty, C=C, fit_intercept=fit_B0, n_jobs=4, solver='saga').fit(X, y)\n",
    "\n",
    "    def score_LogisticRegression(self, trained_LogisticRegression_model, X_test, y_test):\n",
    "        return trained_LogisticRegression_model.score(X_test, y_test)\n",
    "\n",
    "    def predict_LogisticRegression(self, trained_LogisticRegression_model, X_test):\n",
    "        return trained_LogisticRegression_model.predict(X_test)\n",
    "\n",
    "    def optimize_LogisticRegression_params(self, X_train, y_train, penalty_options=penalty_options, C_options=C_options, intercept_options=intercept_options, l1_ratio_options=l1_ratio_options, cv=10, scoring='accuracy'):\n",
    "        LogisticRegression_raw = LogisticRegression()\n",
    "        cv_train_model = GridSearchCV(LogisticRegression_raw, param_grid={'penalty':penalty_options, 'C': C_options, 'fit_intercept':intercept_options, 'l1_ratio':l1_ratio_options}, cv=cv, scoring=scoring).fit(X_train, y_train)\n",
    "        print(f'Best LogisticRegression parameters: penalty = {cv_train_model.best_params_[\"penalty\"]}, C = {cv_train_model.best_params_[\"C\"]}, fit_intercept = {cv_train_model.best_params_[\"fit_intercept\"]}, l1_ratio = {cv_train_model.best_params_[\"l1_ratio\"]}')\n",
    "        best_model = self.train_LogisticRegression(X_train, y_train, penalty=cv_train_model.best_params_[\"penalty\"], C=cv_train_model.best_params_[\"C\"], fit_B0=cv_train_model.best_params_[\"fit_intercept\"], l1_ratio=cv_train_model.best_params_[\"l1_ratio\"])\n",
    "        return best_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression parameters: penalty = l2, C = 0.7525, fit_intercept = True, l1_ratio = 0.0\n",
      "Raw data LogisticRegression optimal score = 0.7166304078429213\n",
      "Time taken = 14484.176457881927\n"
     ]
    }
   ],
   "source": [
    "testLR = pLogisticRegression()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ced7bbea2155d302b976f4184419b8d40f50030e781605408c0dc76f430f24"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('math637')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
